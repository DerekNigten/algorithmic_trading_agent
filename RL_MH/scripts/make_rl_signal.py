import pandas as pd
import numpy as np
from pathlib import Path


def _load_lengths(data_dir: Path) -> tuple[int, int, int]:
    train_path = data_dir / "train_data.csv"
    val_path = data_dir / "val_data.csv"
    test_path = data_dir / "test_data.csv"

    if not train_path.exists() or not val_path.exists() or not test_path.exists():
        raise FileNotFoundError(
            f"Expected train/val/test CSVs in {data_dir}, "
            "please run prepare_data.py first."
        )

    n_train = sum(1 for _ in open(train_path)) - 1
    n_val = sum(1 for _ in open(val_path)) - 1
    n_test = sum(1 for _ in open(test_path)) - 1
    return n_train, n_val, n_test


def _extract_prob_up(df: pd.DataFrame) -> np.ndarray:
    if "prob_up" not in df.columns:
        raise KeyError("Column 'prob_up' not found in prediction file.")
    return df["prob_up"].to_numpy(dtype=float)


def _build_from_test_only(test_path: Path, n_train: int, n_val: int, n_test: int) -> np.ndarray:
    df_test = pd.read_csv(test_path)
    sig_test = _extract_prob_up(df_test)
    if len(sig_test) == n_test:
        missing_test = 0
    elif len(sig_test) < n_test:
        # 常見情況：序列模型因為 lookback window 少掉前面幾筆
        missing_test = n_test - len(sig_test)
        print(
            f"[make_rl_signal] Warning: test predictions shorter than test_data "
            f"({len(sig_test)} vs {n_test}) for {test_path}. "
            f"Filling first {missing_test} test rows with 0 signal."
        )
    else:
        # 預測比資料還多，這比較可疑，保守起見直接報錯
        raise ValueError(
            f"Test prediction length {len(sig_test)} is greater than test_data.csv rows {n_test} "
            f"for file {test_path}. Please check alignment."
        )

    # train/val 全部用 0，test 前面 missing_test 也用 0 當 placeholder
    prefix = np.zeros(n_train + n_val + missing_test, dtype=float)
    return np.concatenate([prefix, sig_test])


def _build_from_splits(train_path: Path, val_path: Path, test_path: Path,
                       n_train: int, n_val: int, n_test: int) -> np.ndarray:
    df_train = pd.read_csv(train_path)
    df_val = pd.read_csv(val_path)
    df_test = pd.read_csv(test_path)

    sig_train = _extract_prob_up(df_train)
    sig_val = _extract_prob_up(df_val)
    sig_test = _extract_prob_up(df_test)

    len_train, len_val, len_test = len(sig_train), len(sig_val), len(sig_test)

    # 完全對齊的情況，直接回傳
    if len_train == n_train and len_val == n_val and len_test == n_test:
        return np.concatenate([sig_train, sig_val, sig_test])

    # 比較穩健的對齊：每個 split 各自獨立處理（trim 尾端 / pad 開頭）
    # 這能處理「有的 split 多、有的 split 少」的混合情況，避免整條退化成 0。
    def _align_one(sig: np.ndarray, n: int, split_name: str) -> np.ndarray:
        if len(sig) == n:
            return sig
        if len(sig) > n:
            extra = len(sig) - n
            print(
                "[make_rl_signal] Warning: predictions longer than data "
                f"for {train_path.parent.name} ({split_name}): pred={len(sig)} vs data={n} "
                f"(trim {extra}); keeping last n rows."
            )
            return sig[-n:]
        missing = n - len(sig)
        print(
            "[make_rl_signal] Warning: predictions shorter than data "
            f"for {train_path.parent.name} ({split_name}): pred={len(sig)} vs data={n} "
            f"(pad {missing}); padding start with zeros."
        )
        return np.concatenate([np.zeros(missing, dtype=float), sig])

    sig_train = _align_one(sig_train, n_train, "train")
    sig_val = _align_one(sig_val, n_val, "val")
    sig_test = _align_one(sig_test, n_test, "test")
    return np.concatenate([sig_train, sig_val, sig_test])



def main() -> None:
    # 專案根目錄（此檔案位於 project/scripts/ 底下）
    root = Path(__file__).resolve().parents[1]

    # prepare_data.py 預設輸出位置
    data_dir = Path("~/Desktop/code/group_01_project/hft_gitlab/data").expanduser()
    n_train, n_val, n_test = _load_lengths(data_dir)
    total_len = n_train + n_val + n_test

    # Predictions generated by scripts/gerenate_prediction.py (split-based, aligned)
    pred_dir = root / "RL_signal" / "model"
    pred_dir.mkdir(parents=True, exist_ok=True)

    # Final RL signals consumed by RL pipeline
    out_dir = root / "RL_signal"
    out_dir.mkdir(parents=True, exist_ok=True)

    # === 1. LSTM：train/val/test predictions are produced and aligned already ===
    lstm_train = pred_dir / "lstm_train_predictions.csv"
    lstm_val = pred_dir / "lstm_val_predictions.csv"
    lstm_test = pred_dir / "lstm_test_predictions.csv"
    sig_lstm = _build_from_splits(lstm_train, lstm_val, lstm_test, n_train, n_val, n_test)
    pd.DataFrame({"prediction": sig_lstm}).to_csv(out_dir / "rl_signal_lstm.csv", index=False)

    # === 2. TCN：train/val/test predictions are produced and aligned already ===
    tcn_train = pred_dir / "tcn_train_predictions.csv"
    tcn_val = pred_dir / "tcn_val_predictions.csv"
    tcn_test = pred_dir / "tcn_test_predictions.csv"
    sig_tcn = _build_from_splits(tcn_train, tcn_val, tcn_test, n_train, n_val, n_test)
    pd.DataFrame({"prediction": sig_tcn}).to_csv(out_dir / "rl_signal_tcn.csv", index=False)

    # === 3. Transformer：train/val/test predictions are produced and aligned already ===
    transf_train = pred_dir / "transformer_train_predictions.csv"
    transf_val = pred_dir / "transformer_val_predictions.csv"
    transf_test = pred_dir / "transformer_test_predictions.csv"
    sig_transf = _build_from_splits(transf_train, transf_val, transf_test, n_train, n_val, n_test)
    pd.DataFrame({"prediction": sig_transf}).to_csv(out_dir / "rl_signal_transformer.csv", index=False)

    # === 4. XGBoost：train/val/test predictions are copied/generated under RL_signal/model ===
    xgb_train = pred_dir / "xgb_train_predictions.csv"
    xgb_val = pred_dir / "xgb_val_predictions.csv"
    xgb_test = pred_dir / "xgb_test_predictions.csv"
    sig_xgb = _build_from_splits(xgb_train, xgb_val, xgb_test, n_train, n_val, n_test)
    pd.DataFrame({"prediction": sig_xgb}).to_csv(out_dir / "rl_signal_xgb.csv", index=False)

    print("RL signals generated:")
    print(f"  length per signal = {total_len}")
    print(f"  LSTM:        {out_dir / 'rl_signal_lstm.csv'}")
    print(f"  TCN:         {out_dir / 'rl_signal_tcn.csv'}")
    print(f"  Transformer: {out_dir / 'rl_signal_transformer.csv'}")
    print(f"  XGBoost:     {out_dir / 'rl_signal_xgb.csv'}")


if __name__ == "__main__":
    main()
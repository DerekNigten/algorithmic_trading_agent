{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4141c94-b800-4c48-aef5-4f7493126840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4: TEST TRAINED RL AGENT\n",
      "============================================================\n",
      "\n",
      "Input path: C:\\Users\\wdkal\\Downloads\\RL_INPUTS\n",
      "Model path: C:\\Users\\wdkal\\Downloads\\RL_OUTPUTS\n",
      "Output path: C:\\Users\\wdkal\\Downloads\\TEST_RESULTS\n",
      "\n",
      "============================================================\n",
      "LOADING TEST DATA AND MODEL\n",
      "============================================================\n",
      "\n",
      "Loading test environment...\n",
      "  Loaded 3,496,512 test events\n",
      "\n",
      "Loading trained agent...\n",
      "  âœ“ Loaded trained model from C:\\Users\\wdkal\\Downloads\\RL_OUTPUTS\\best_agent.pt\n",
      "  âœ“ Model epsilon: 0.493\n",
      "\n",
      "============================================================\n",
      "RUNNING TEST\n",
      "============================================================\n",
      "\n",
      "Testing agent on Days 14-15...\n",
      "Progress: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wdkal\\AppData\\Local\\Temp\\ipykernel_13808\\4256332399.py:232: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,000...20,000...30,000...40,000...50,000...60,000...70,000...80,000...90,000...100,000...110,000...120,000...130,000...140,000...150,000...160,000...170,000...180,000...190,000...200,000...210,000...220,000...230,000...240,000...250,000...260,000...270,000...280,000...290,000...300,000...310,000...320,000...330,000...340,000...350,000...360,000...370,000...380,000...390,000...400,000...410,000...420,000...430,000...440,000...450,000...460,000...470,000...480,000...490,000...500,000...510,000...520,000...530,000...540,000...550,000...560,000...570,000...580,000...590,000...600,000...610,000...620,000...630,000...640,000...650,000...660,000...670,000...680,000...690,000...700,000...710,000...720,000...730,000...740,000...750,000...760,000...770,000...780,000...790,000...800,000...810,000...820,000...830,000...840,000...850,000...860,000...870,000...880,000...890,000...900,000...910,000...920,000...930,000...940,000...950,000...960,000...970,000...980,000...990,000...1,000,000...1,010,000...1,020,000...1,030,000...1,040,000...1,050,000...1,060,000...1,070,000...1,080,000...1,090,000...1,100,000...1,110,000...1,120,000...1,130,000...1,140,000...1,150,000...1,160,000...1,170,000...1,180,000...1,190,000...1,200,000...1,210,000...1,220,000...1,230,000...1,240,000...1,250,000...1,260,000...1,270,000...1,280,000...1,290,000...1,300,000...1,310,000...1,320,000...1,330,000...1,340,000...1,350,000...1,360,000...1,370,000...1,380,000...1,390,000...1,400,000...1,410,000...1,420,000...1,430,000...1,440,000...1,450,000...1,460,000...1,470,000...1,480,000...1,490,000...1,500,000...1,510,000...1,520,000...1,530,000...1,540,000...1,550,000...1,560,000...1,570,000...1,580,000...1,590,000...1,600,000...1,610,000...1,620,000...1,630,000...1,640,000...1,650,000...1,660,000...1,670,000...1,680,000...1,690,000...1,700,000...1,710,000...1,720,000...1,730,000...1,740,000...1,750,000...1,760,000...1,770,000...1,780,000...1,790,000...1,800,000...1,810,000...1,820,000...1,830,000...1,840,000...1,850,000...1,860,000...1,870,000...1,880,000...1,890,000...1,900,000...1,910,000...1,920,000...1,930,000...1,940,000...1,950,000...1,960,000...1,970,000...1,980,000...1,990,000...2,000,000...2,010,000...2,020,000...2,030,000...2,040,000...2,050,000...2,060,000...2,070,000...2,080,000...2,090,000...2,100,000...2,110,000...2,120,000...2,130,000...2,140,000...2,150,000...2,160,000...2,170,000...2,180,000...2,190,000...2,200,000...2,210,000...2,220,000...2,230,000...2,240,000...2,250,000...2,260,000...2,270,000...2,280,000...2,290,000...2,300,000...2,310,000...2,320,000...2,330,000...2,340,000...2,350,000...2,360,000...2,370,000...2,380,000...2,390,000...2,400,000...2,410,000...2,420,000...2,430,000...2,440,000...2,450,000...2,460,000...2,470,000...2,480,000...2,490,000...2,500,000...2,510,000...2,520,000...2,530,000...2,540,000...2,550,000...2,560,000...2,570,000...2,580,000...2,590,000...2,600,000...2,610,000...2,620,000...2,630,000...2,640,000...2,650,000...2,660,000...2,670,000...2,680,000...2,690,000...2,700,000...2,710,000...2,720,000...2,730,000...2,740,000...2,750,000...2,760,000...2,770,000...2,780,000...2,790,000...2,800,000...2,810,000...2,820,000...2,830,000...2,840,000...2,850,000...2,860,000...2,870,000...2,880,000...2,890,000...2,900,000...2,910,000...2,920,000...2,930,000...2,940,000...2,950,000...2,960,000...2,970,000...2,980,000...2,990,000...3,000,000...3,010,000...3,020,000...3,030,000...3,040,000...3,050,000...3,060,000...3,070,000...3,080,000...3,090,000...3,100,000...3,110,000...3,120,000...3,130,000...3,140,000...3,150,000...3,160,000...3,170,000...3,180,000...3,190,000...3,200,000...3,210,000...3,220,000...3,230,000...3,240,000...3,250,000...3,260,000...3,270,000...3,280,000...3,290,000...3,300,000...3,310,000...3,320,000...3,330,000...3,340,000...3,350,000...3,360,000...3,370,000...3,380,000...3,390,000...3,400,000...3,410,000...3,420,000...3,430,000...3,440,000...3,450,000...3,460,000...3,470,000...3,480,000...3,490,000... Done! (3,496,512 steps in 5493.3s)\n",
      "\n",
      "============================================================\n",
      "TEST RESULTS - DAYS 14-15\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Performance Metrics:\n",
      "  Total PnL:        $-644,843.28\n",
      "  Sharpe Ratio:     -7.31\n",
      "  Max Drawdown:     $-692,606.95\n",
      "  Number of Trades: 3,279\n",
      "  Win Rate:         42.8%\n",
      "  Avg Win:          $23.88\n",
      "  Avg Loss:         $-16.83\n",
      "  Final Position:   -1.00\n",
      "\n",
      "ðŸ“ˆ Action Distribution:\n",
      "  Sell L  :      0 (  0.0%)\n",
      "  Sell M  : 3,471,462 ( 99.3%)\n",
      "  Sell S  :      5 (  0.0%)\n",
      "  HOLD    :  5,624 (  0.2%)\n",
      "  Buy S   :      6 (  0.0%)\n",
      "  Buy M   : 15,687 (  0.4%)\n",
      "  Buy L   :  3,728 (  0.1%)\n",
      "\n",
      "============================================================\n",
      "SAVING RESULTS\n",
      "============================================================\n",
      "\n",
      "âœ“ Saved detailed results to C:\\Users\\wdkal\\Downloads\\TEST_RESULTS\\test_results.pkl\n",
      "\n",
      "============================================================\n",
      "CREATING VISUALIZATIONS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wdkal\\AppData\\Local\\Temp\\ipykernel_13808\\4256332399.py:411: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(TEST_OUTPUT_PATH / 'test_results_visualization.png', dpi=150, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Saved visualization to C:\\Users\\wdkal\\Downloads\\TEST_RESULTS\\test_results_visualization.png\n",
      "\n",
      "============================================================\n",
      "SAMPLE TRADES (First 10)\n",
      "============================================================\n",
      "\n",
      "    Step   Action  Old Pos  New Pos   Change        PnL    Cum PnL\n",
      "--------------------------------------------------------------------------\n",
      "       1   Sell M     0.00    -0.30    -0.30 $    14.96 $    14.96\n",
      "       2    Buy M    -0.30     0.00     0.30 $    -0.03 $    14.93\n",
      "       3   Sell M     0.00    -0.30    -0.30 $    14.96 $    29.89\n",
      "       4    Buy M    -0.30     0.00     0.30 $    -0.03 $    29.86\n",
      "       5   Sell M     0.00    -0.30    -0.30 $    -0.04 $    29.82\n",
      "       7    Buy M    -0.30     0.00     0.30 $    -0.03 $    14.78\n",
      "       8   Sell M     0.00    -0.30    -0.30 $   -15.04 $    -0.25\n",
      "       9    Buy M    -0.30     0.00     0.30 $    -0.03 $    -0.28\n",
      "      10   Sell M     0.00    -0.30    -0.30 $   -15.04 $   -15.32\n",
      "      11    Buy M    -0.30     0.00     0.30 $    -0.03 $   -15.35\n",
      "... (3,269 more trades)\n",
      "\n",
      "============================================================\n",
      "âœ… TESTING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Key Results:\n",
      "  â€¢ Final PnL: $-644,843.28\n",
      "  â€¢ Sharpe Ratio: -7.31\n",
      "  â€¢ Total Trades: 3,279\n",
      "  â€¢ Test Duration: 5493.3 seconds\n",
      "\n",
      "Output Files:\n",
      "  â€¢ Results: C:\\Users\\wdkal\\Downloads\\TEST_RESULTS\\test_results.pkl\n",
      "  â€¢ Visualization: C:\\Users\\wdkal\\Downloads\\TEST_RESULTS\\test_results_visualization.png\n",
      "\n",
      "ðŸŽ‰ RL Agent Testing Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4: Test Trained RL Agent on Days 14-15\n",
    "Evaluates the trained Double DQN agent on test data\n",
    "Run this after Step 3 (Train_RL_Agent.py)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 4: TEST TRAINED RL AGENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# PATHS\n",
    "# ============================================================\n",
    "RL_INPUT_PATH = Path(\"C:/Users/wdkal/Downloads/RL_INPUTS\")\n",
    "RL_OUTPUT_PATH = Path(\"C:/Users/wdkal/Downloads/RL_OUTPUTS\")\n",
    "TEST_OUTPUT_PATH = Path(\"C:/Users/wdkal/Downloads/TEST_RESULTS\")\n",
    "TEST_OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nInput path: {RL_INPUT_PATH}\")\n",
    "print(f\"Model path: {RL_OUTPUT_PATH}\")\n",
    "print(f\"Output path: {TEST_OUTPUT_PATH}\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD TRADING ENVIRONMENT (Same as training)\n",
    "# ============================================================\n",
    "\n",
    "class TradingEnvironment:\n",
    "    \"\"\"Trading environment for testing\"\"\"\n",
    "    def __init__(self, rl_input_path, transaction_cost=0.001):\n",
    "        with open(rl_input_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        self.xgb_preds = data['predictions']['xgb']\n",
    "        self.lstm_preds = data['predictions']['lstm']\n",
    "        self.tcn_preds = data['predictions']['tcn']\n",
    "        self.transformer_preds = data['predictions']['transformer']\n",
    "        self.actual_labels = data['actual_labels']\n",
    "        \n",
    "        self.num_events = len(self.actual_labels)\n",
    "        self.transaction_cost = transaction_cost\n",
    "        \n",
    "        print(f\"  Loaded {self.num_events:,} test events\")\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment to start\"\"\"\n",
    "        self.current_step = 0\n",
    "        self.position = 0.0\n",
    "        self.pnl = 0.0\n",
    "        self.pnl_history = [0.0]\n",
    "        self.trades = []\n",
    "        self.position_history = [0.0]\n",
    "        self.action_history = []\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        \"\"\"Get current state (28 features)\"\"\"\n",
    "        if self.current_step >= self.num_events:\n",
    "            return None\n",
    "        \n",
    "        # Model predictions (12 features)\n",
    "        xgb = self.xgb_preds[self.current_step]\n",
    "        lstm = self.lstm_preds[self.current_step]\n",
    "        tcn = self.tcn_preds[self.current_step]\n",
    "        transformer = self.transformer_preds[self.current_step]\n",
    "        \n",
    "        # Ensemble stats (4 features)\n",
    "        all_probs = np.array([xgb, lstm, tcn, transformer])\n",
    "        mean_up = np.mean(all_probs[:, 2])\n",
    "        mean_neutral = np.mean(all_probs[:, 1])\n",
    "        mean_down = np.mean(all_probs[:, 0])\n",
    "        std_up = np.std(all_probs[:, 2])\n",
    "        \n",
    "        # Market features (5 features)\n",
    "        price_trend = mean_up - mean_down\n",
    "        confidence = max(mean_up, mean_neutral, mean_down)\n",
    "        uncertainty = std_up\n",
    "        non_neutral = mean_up + mean_down\n",
    "        time_progress = float(self.current_step) / self.num_events\n",
    "        \n",
    "        # Trading state (7 features)\n",
    "        num_recent_trades = len([t for t in self.trades if t['step'] > self.current_step - 100])\n",
    "        recent_pnl = self.pnl_history[-1]\n",
    "        \n",
    "        state = np.concatenate([\n",
    "            xgb, lstm, tcn, transformer,  # 12\n",
    "            [mean_up, mean_neutral, mean_down, std_up],  # 4\n",
    "            [price_trend, confidence, uncertainty, non_neutral, time_progress],  # 5\n",
    "            [self.position, recent_pnl/100, num_recent_trades/10, \n",
    "             self.current_step/self.num_events, abs(self.position),\n",
    "             1.0 if self.position > 0 else 0.0, 1.0 if self.position < 0 else 0.0]  # 7\n",
    "        ])\n",
    "        \n",
    "        return state.astype(np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take action and return next state, reward, done\"\"\"\n",
    "        # Action mapping\n",
    "        action_map = {0: -0.5, 1: -0.3, 2: -0.1, 3: 0.0, 4: 0.1, 5: 0.3, 6: 0.5}\n",
    "        position_change = action_map[action]\n",
    "        \n",
    "        old_position = self.position\n",
    "        new_position = np.clip(self.position + position_change, -1.0, 1.0)\n",
    "        actual_change = new_position - old_position\n",
    "        \n",
    "        # Transaction cost\n",
    "        cost = abs(actual_change) * self.transaction_cost * 100\n",
    "        \n",
    "        self.position = new_position\n",
    "        self.position_history.append(self.position)\n",
    "        self.action_history.append(action)\n",
    "        self.current_step += 1\n",
    "        \n",
    "        done = False\n",
    "        reward = 0\n",
    "        \n",
    "        if self.current_step < self.num_events:\n",
    "            # Price movement\n",
    "            actual_label = self.actual_labels[self.current_step]\n",
    "            price_movement = (actual_label - 1) * 0.5  # -0.5, 0, +0.5\n",
    "            \n",
    "            # PnL = position Ã— price_movement Ã— scale - transaction cost\n",
    "            pnl = self.position * price_movement * 100\n",
    "            reward = pnl - cost - 0.1 * (self.position ** 2)\n",
    "            \n",
    "            self.pnl += reward\n",
    "            self.pnl_history.append(self.pnl)\n",
    "            \n",
    "            # Track trades\n",
    "            if actual_change != 0:\n",
    "                self.trades.append({\n",
    "                    'step': self.current_step,\n",
    "                    'action': action,\n",
    "                    'old_position': old_position,\n",
    "                    'new_position': self.position,\n",
    "                    'change': actual_change,\n",
    "                    'pnl': reward,\n",
    "                    'cumulative_pnl': self.pnl\n",
    "                })\n",
    "        else:\n",
    "            done = True\n",
    "        \n",
    "        next_state = self.get_state()\n",
    "        return next_state, reward, done, {}\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        \"\"\"Calculate comprehensive performance metrics\"\"\"\n",
    "        if len(self.pnl_history) < 2:\n",
    "            return {\n",
    "                'total_pnl': 0, 'sharpe': 0, 'num_trades': 0, \n",
    "                'max_drawdown': 0, 'win_rate': 0, 'avg_win': 0, 'avg_loss': 0\n",
    "            }\n",
    "        \n",
    "        total_pnl = self.pnl_history[-1]\n",
    "        returns = np.diff(self.pnl_history)\n",
    "        mean_return = np.mean(returns)\n",
    "        std_return = np.std(returns) if len(returns) > 1 else 1\n",
    "        \n",
    "        # Sharpe ratio\n",
    "        sharpe = (mean_return / std_return) * np.sqrt(len(returns)) if std_return > 0 else 0\n",
    "        \n",
    "        # Max drawdown\n",
    "        cummax = np.maximum.accumulate(self.pnl_history)\n",
    "        drawdown = np.array(self.pnl_history) - cummax\n",
    "        max_drawdown = np.min(drawdown)\n",
    "        \n",
    "        # Win rate and avg win/loss\n",
    "        trade_pnls = [t['pnl'] for t in self.trades]\n",
    "        if len(trade_pnls) > 0:\n",
    "            wins = [p for p in trade_pnls if p > 0]\n",
    "            losses = [p for p in trade_pnls if p < 0]\n",
    "            win_rate = len(wins) / len(trade_pnls) if len(trade_pnls) > 0 else 0\n",
    "            avg_win = np.mean(wins) if len(wins) > 0 else 0\n",
    "            avg_loss = np.mean(losses) if len(losses) > 0 else 0\n",
    "        else:\n",
    "            win_rate = 0\n",
    "            avg_win = 0\n",
    "            avg_loss = 0\n",
    "        \n",
    "        return {\n",
    "            'total_pnl': total_pnl,\n",
    "            'num_trades': len(self.trades),\n",
    "            'sharpe': sharpe,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'win_rate': win_rate,\n",
    "            'avg_win': avg_win,\n",
    "            'avg_loss': avg_loss,\n",
    "            'final_position': self.position\n",
    "        }\n",
    "\n",
    "# ============================================================\n",
    "# LOAD AGENT\n",
    "# ============================================================\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Q-Network (same architecture as training)\"\"\"\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=128):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, action_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, state):\n",
    "        return self.network(state)\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"Agent for testing (no training, just inference)\"\"\"\n",
    "    def __init__(self, model_path):\n",
    "        self.policy_net = QNetwork(state_dim=28, action_dim=7)\n",
    "        \n",
    "        # Load trained model\n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "        self.policy_net.load_state_dict(checkpoint['policy_net'])\n",
    "        self.policy_net.eval()  # Set to evaluation mode\n",
    "        \n",
    "        print(f\"  âœ“ Loaded trained model from {model_path}\")\n",
    "        print(f\"  âœ“ Model epsilon: {checkpoint['epsilon']:.3f}\")\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        \"\"\"Select action (greedy, no exploration)\"\"\"\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "            q_values = self.policy_net(state_tensor)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "# ============================================================\n",
    "# TEST AGENT\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING TEST DATA AND MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load test environment\n",
    "print(\"\\nLoading test environment...\")\n",
    "test_env = TradingEnvironment(RL_INPUT_PATH / \"rl_input_test.pkl\")\n",
    "\n",
    "# Load trained agent\n",
    "print(\"\\nLoading trained agent...\")\n",
    "agent = Agent(RL_OUTPUT_PATH / \"best_agent.pt\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = datetime.now()\n",
    "state = test_env.reset()\n",
    "step = 0\n",
    "\n",
    "print(\"\\nTesting agent on Days 14-15...\")\n",
    "print(\"Progress: \", end='', flush=True)\n",
    "\n",
    "# Run test\n",
    "while state is not None:\n",
    "    action = agent.select_action(state)\n",
    "    state, reward, done, _ = test_env.step(action)\n",
    "    step += 1\n",
    "    \n",
    "    # Progress indicator\n",
    "    if step % 10000 == 0:\n",
    "        print(f\"{step:,}...\", end='', flush=True)\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "test_time = (datetime.now() - start_time).total_seconds()\n",
    "print(f\" Done! ({step:,} steps in {test_time:.1f}s)\")\n",
    "\n",
    "# Get metrics\n",
    "metrics = test_env.get_metrics()\n",
    "\n",
    "# ============================================================\n",
    "# RESULTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST RESULTS - DAYS 14-15\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nðŸ“Š Performance Metrics:\")\n",
    "print(f\"  Total PnL:        ${metrics['total_pnl']:,.2f}\")\n",
    "print(f\"  Sharpe Ratio:     {metrics['sharpe']:.2f}\")\n",
    "print(f\"  Max Drawdown:     ${metrics['max_drawdown']:,.2f}\")\n",
    "print(f\"  Number of Trades: {metrics['num_trades']:,}\")\n",
    "print(f\"  Win Rate:         {metrics['win_rate']*100:.1f}%\")\n",
    "print(f\"  Avg Win:          ${metrics['avg_win']:.2f}\")\n",
    "print(f\"  Avg Loss:         ${metrics['avg_loss']:.2f}\")\n",
    "print(f\"  Final Position:   {metrics['final_position']:.2f}\")\n",
    "\n",
    "# Action distribution\n",
    "action_counts = np.bincount(test_env.action_history, minlength=7)\n",
    "action_names = ['Sell L', 'Sell M', 'Sell S', 'HOLD', 'Buy S', 'Buy M', 'Buy L']\n",
    "print(f\"\\nðŸ“ˆ Action Distribution:\")\n",
    "for i, (name, count) in enumerate(zip(action_names, action_counts)):\n",
    "    pct = count / len(test_env.action_history) * 100\n",
    "    print(f\"  {name:8s}: {count:6,} ({pct:5.1f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save detailed results\n",
    "results = {\n",
    "    'metrics': metrics,\n",
    "    'pnl_history': test_env.pnl_history,\n",
    "    'position_history': test_env.position_history,\n",
    "    'action_history': test_env.action_history,\n",
    "    'trades': test_env.trades,\n",
    "    'action_distribution': dict(zip(action_names, action_counts.tolist()))\n",
    "}\n",
    "\n",
    "with open(TEST_OUTPUT_PATH / 'test_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "print(f\"\\nâœ“ Saved detailed results to {TEST_OUTPUT_PATH / 'test_results.pkl'}\")\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZATIONS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(4, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Cumulative PnL\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.plot(test_env.pnl_history, linewidth=1.5, color='darkblue')\n",
    "ax1.set_title('Cumulative PnL Over Time', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Step')\n",
    "ax1.set_ylabel('Cumulative PnL ($)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.fill_between(range(len(test_env.pnl_history)), test_env.pnl_history, 0, \n",
    "                  alpha=0.3, color='green' if test_env.pnl_history[-1] > 0 else 'red')\n",
    "\n",
    "# 2. Position Over Time\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "ax2.plot(test_env.position_history, linewidth=1, color='purple')\n",
    "ax2.set_title('Position Over Time', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Step')\n",
    "ax2.set_ylabel('Position')\n",
    "ax2.set_ylim(-1.1, 1.1)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax2.axhline(y=1, color='green', linestyle='--', alpha=0.3, label='Long')\n",
    "ax2.axhline(y=-1, color='red', linestyle='--', alpha=0.3, label='Short')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Action Distribution\n",
    "ax3 = fig.add_subplot(gs[2, 0])\n",
    "colors = ['darkred', 'red', 'lightcoral', 'gray', 'lightgreen', 'green', 'darkgreen']\n",
    "bars = ax3.bar(action_names, action_counts, color=colors, alpha=0.7)\n",
    "ax3.set_title('Action Distribution', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height):,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Trade PnL Distribution\n",
    "ax4 = fig.add_subplot(gs[2, 1])\n",
    "if len(test_env.trades) > 0:\n",
    "    trade_pnls = [t['pnl'] for t in test_env.trades]\n",
    "    ax4.hist(trade_pnls, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    ax4.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "    ax4.set_title('Trade PnL Distribution', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xlabel('PnL per Trade ($)')\n",
    "    ax4.set_ylabel('Frequency')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 5. Drawdown\n",
    "ax5 = fig.add_subplot(gs[3, :])\n",
    "cummax = np.maximum.accumulate(test_env.pnl_history)\n",
    "drawdown = np.array(test_env.pnl_history) - cummax\n",
    "ax5.fill_between(range(len(drawdown)), drawdown, 0, alpha=0.5, color='red')\n",
    "ax5.plot(drawdown, color='darkred', linewidth=1)\n",
    "ax5.set_title('Drawdown Over Time', fontsize=14, fontweight='bold')\n",
    "ax5.set_xlabel('Step')\n",
    "ax5.set_ylabel('Drawdown ($)')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "ax5.axhline(y=metrics['max_drawdown'], color='red', linestyle='--', \n",
    "            label=f\"Max DD: ${metrics['max_drawdown']:.2f}\", alpha=0.7)\n",
    "ax5.legend()\n",
    "\n",
    "plt.savefig(TEST_OUTPUT_PATH / 'test_results_visualization.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"\\nâœ“ Saved visualization to {TEST_OUTPUT_PATH / 'test_results_visualization.png'}\")\n",
    "\n",
    "# ============================================================\n",
    "# TRADE ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "if len(test_env.trades) > 0:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SAMPLE TRADES (First 10)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n{'Step':>8} {'Action':>8} {'Old Pos':>8} {'New Pos':>8} {'Change':>8} {'PnL':>10} {'Cum PnL':>10}\")\n",
    "    print(\"-\" * 74)\n",
    "    \n",
    "    for i, trade in enumerate(test_env.trades[:10]):\n",
    "        action_name = action_names[trade['action']]\n",
    "        print(f\"{trade['step']:8,} {action_name:>8} {trade['old_position']:8.2f} \"\n",
    "              f\"{trade['new_position']:8.2f} {trade['change']:8.2f} \"\n",
    "              f\"${trade['pnl']:9.2f} ${trade['cumulative_pnl']:9.2f}\")\n",
    "    \n",
    "    if len(test_env.trades) > 10:\n",
    "        print(f\"... ({len(test_env.trades) - 10:,} more trades)\")\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… TESTING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nKey Results:\")\n",
    "print(f\"  â€¢ Final PnL: ${metrics['total_pnl']:,.2f}\")\n",
    "print(f\"  â€¢ Sharpe Ratio: {metrics['sharpe']:.2f}\")\n",
    "print(f\"  â€¢ Total Trades: {metrics['num_trades']:,}\")\n",
    "print(f\"  â€¢ Test Duration: {test_time:.1f} seconds\")\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"  â€¢ Results: {TEST_OUTPUT_PATH / 'test_results.pkl'}\")\n",
    "print(f\"  â€¢ Visualization: {TEST_OUTPUT_PATH / 'test_results_visualization.png'}\")\n",
    "print(\"\\nðŸŽ‰ RL Agent Testing Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_fresh",
   "language": "python",
   "name": "pytorch_fresh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

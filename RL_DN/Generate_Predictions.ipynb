{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7902bf6-b1ef-4a2b-8eea-29b9a28c8972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Imports...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 1: Generate predictions from all 4 models on Days 6-15\n",
    "Complete standalone script - FIXED TCN BUG\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# PATHS\n",
    "# ============================================================\n",
    "RAW_DATA_PATH = Path(\"C:/Users/wdkal/iex_data/book_snapshots\")\n",
    "MODEL_PATH = Path(\"C:/Users/wdkal/Downloads/RL_Model\")\n",
    "OUTPUT_PATH = Path(\"C:/Users/wdkal/Downloads/NEW_PREDICTIONS\")\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NEW_DAYS = [\n",
    "    '20251027', '20251028', '20251029', '20251030', '20251031',\n",
    "    '20251103', '20251104', '20251105', '20251106', '20251107'\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# MODEL ARCHITECTURES\n",
    "# ============================================================\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, fc1_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc1(lstm_out[:, -1, :])\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, \n",
    "                              padding=padding, dilation=dilation)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, \n",
    "                              padding=padding, dilation=dilation)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))  # FIXED: was self.conv2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            res = self.downsample(x)\n",
    "        else:\n",
    "            res = x\n",
    "        \n",
    "        if out.size(2) != res.size(2):\n",
    "            out = out[:, :, :res.size(2)]\n",
    "        \n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, output_size=3):\n",
    "        super(TCNModel, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation = 2 ** i\n",
    "            in_ch = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_ch = num_channels[i]\n",
    "            layers.append(TemporalBlock(in_ch, out_ch, kernel_size, dilation))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(num_channels[-1], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.network(x)\n",
    "        out = out[:, :, -1]\n",
    "        return self.fc(out)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pe = nn.Parameter(torch.randn(1, max_len, d_model))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, d_model, nhead, num_layers, dim_feedforward, fc1_size, output_size, max_len=5000):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_projection = nn.Linear(input_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc1 = nn.Linear(d_model, fc1_size)\n",
    "        self.fc2 = nn.Linear(fc1_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD ALL 4 MODELS\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING ALL 4 MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. XGBoost\n",
    "print(\"\\nLoading XGBoost...\")\n",
    "xgb_model = xgb.Booster()\n",
    "xgb_model.load_model(MODEL_PATH / \"xgb_best_model.json\")\n",
    "print(\"✓ XGBoost loaded\")\n",
    "\n",
    "# 2. LSTM\n",
    "print(\"Loading LSTM...\")\n",
    "lstm_state = torch.load(MODEL_PATH / \"lstm_best_model.pt\", map_location='cpu', weights_only=False)\n",
    "weight_ih = lstm_state['lstm.weight_ih_l0']\n",
    "input_size = weight_ih.shape[1]\n",
    "hidden_size = weight_ih.shape[0] // 4\n",
    "fc1_size = lstm_state['fc1.weight'].shape[0]\n",
    "output_size = lstm_state['fc2.weight'].shape[0]\n",
    "lstm_model = LSTMModel(input_size, hidden_size, 2, fc1_size, output_size)\n",
    "lstm_model.load_state_dict(lstm_state)\n",
    "lstm_model.eval()\n",
    "print(f\"✓ LSTM loaded (input={input_size}, hidden={hidden_size})\")\n",
    "\n",
    "# 3. TCN\n",
    "print(\"Loading TCN...\")\n",
    "tcn_state = torch.load(MODEL_PATH / \"tcn_best_model.pt\", map_location='cpu', weights_only=False)\n",
    "\n",
    "if 'network.0.conv1.conv.weight' in tcn_state:\n",
    "    first_conv_weight = tcn_state['network.0.conv1.conv.weight']\n",
    "    conv_key_pattern = 'network.{}.conv1.conv.weight'\n",
    "elif 'network.0.conv1.weight' in tcn_state:\n",
    "    first_conv_weight = tcn_state['network.0.conv1.weight']\n",
    "    conv_key_pattern = 'network.{}.conv1.weight'\n",
    "else:\n",
    "    raise KeyError(\"Cannot find TCN conv weights in state dict\")\n",
    "\n",
    "num_inputs = first_conv_weight.shape[1]\n",
    "kernel_size = first_conv_weight.shape[2]\n",
    "\n",
    "num_channels = []\n",
    "i = 0\n",
    "while conv_key_pattern.format(i) in tcn_state:\n",
    "    num_channels.append(tcn_state[conv_key_pattern.format(i)].shape[0])\n",
    "    i += 1\n",
    "\n",
    "tcn_model = TCNModel(num_inputs, num_channels, kernel_size, output_size=3)\n",
    "\n",
    "if 'network.0.conv1.conv.weight' in tcn_state:\n",
    "    new_state = {}\n",
    "    for key, value in tcn_state.items():\n",
    "        new_key = key.replace('.conv1.conv.', '.conv1.').replace('.conv2.conv.', '.conv2.')\n",
    "        new_state[new_key] = value\n",
    "    tcn_model.load_state_dict(new_state)\n",
    "else:\n",
    "    tcn_model.load_state_dict(tcn_state)\n",
    "\n",
    "tcn_model.eval()\n",
    "print(f\"✓ TCN loaded (input={num_inputs}, channels={num_channels}, kernel={kernel_size})\")\n",
    "\n",
    "# 4. Transformer\n",
    "print(\"Loading Transformer...\")\n",
    "checkpoint = torch.load(MODEL_PATH / \"best_transformer_model.pth\", map_location='cpu', weights_only=False)\n",
    "transformer_state = checkpoint['model_state_dict']\n",
    "hyperparams = checkpoint['hyperparameters']\n",
    "fc1_size = transformer_state['fc1.weight'].shape[0]\n",
    "output_size = transformer_state['fc2.weight'].shape[0]\n",
    "max_len = transformer_state['pos_encoder.pe'].shape[1]\n",
    "transformer_model = TransformerModel(\n",
    "    hyperparams['input_size'], hyperparams['d_model'], hyperparams['nhead'],\n",
    "    hyperparams['num_layers'], hyperparams['dim_feedforward'],\n",
    "    fc1_size, output_size, max_len\n",
    ")\n",
    "transformer_model.load_state_dict(transformer_state)\n",
    "transformer_model.eval()\n",
    "print(f\"✓ Transformer loaded\")\n",
    "\n",
    "print(\"\\n✅ ALL 4 MODELS LOADED SUCCESSFULLY!\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "def add_all_features(df):\n",
    "    features = pd.DataFrame()\n",
    "    features['date'] = df['date']\n",
    "    \n",
    "    features[\"mid_price\"] = (df[\"BID_PRICE_1\"] + df[\"ASK_PRICE_1\"]) / 2\n",
    "    features[\"microprice\"] = (df[\"BID_PRICE_1\"] * df[\"ASK_SIZE_1\"] + df[\"ASK_PRICE_1\"] * df[\"BID_SIZE_1\"]) / (df[\"BID_SIZE_1\"] + df[\"ASK_SIZE_1\"] + 1e-10)\n",
    "    features[\"spread\"] = df[\"ASK_PRICE_1\"] - df[\"BID_PRICE_1\"]\n",
    "    features[\"vol_imbalance\"] = (df[\"BID_SIZE_1\"] - df[\"ASK_SIZE_1\"]) / (df[\"BID_SIZE_1\"] + df[\"ASK_SIZE_1\"] + 1e-6)\n",
    "    features[\"bid_ask_spread_ratio\"] = features[\"spread\"] / features[\"mid_price\"]\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        features[f\"BID_PRICE_{i}\"] = df[f\"BID_PRICE_{i}\"]\n",
    "        features[f\"BID_SIZE_{i}\"] = df[f\"BID_SIZE_{i}\"]\n",
    "        features[f\"ASK_PRICE_{i}\"] = df[f\"ASK_PRICE_{i}\"]\n",
    "        features[f\"ASK_SIZE_{i}\"] = df[f\"ASK_SIZE_{i}\"]\n",
    "    \n",
    "    features[\"bid_price_mean\"] = (df[\"BID_PRICE_1\"] + df[\"BID_PRICE_2\"] + df[\"BID_PRICE_3\"]) / 3\n",
    "    features[\"ask_price_mean\"] = (df[\"ASK_PRICE_1\"] + df[\"ASK_PRICE_2\"] + df[\"ASK_PRICE_3\"]) / 3\n",
    "    features[\"bid_qty_mean\"] = (df[\"BID_SIZE_1\"] + df[\"BID_SIZE_2\"] + df[\"BID_SIZE_3\"]) / 3\n",
    "    features[\"ask_qty_mean\"] = (df[\"ASK_SIZE_1\"] + df[\"ASK_SIZE_2\"] + df[\"ASK_SIZE_3\"]) / 3\n",
    "    \n",
    "    features[\"price_cum_diff\"] = (df[\"ASK_PRICE_1\"] - df[\"BID_PRICE_1\"] + \n",
    "                                  df[\"ASK_PRICE_2\"] - df[\"BID_PRICE_2\"] + \n",
    "                                  df[\"ASK_PRICE_3\"] - df[\"BID_PRICE_3\"])\n",
    "    features[\"qty_cum_diff\"] = (df[\"ASK_SIZE_1\"] - df[\"BID_SIZE_1\"] + \n",
    "                                df[\"ASK_SIZE_2\"] - df[\"BID_SIZE_2\"] + \n",
    "                                df[\"ASK_SIZE_3\"] - df[\"BID_SIZE_3\"])\n",
    "    \n",
    "    features[\"time_delta\"] = 1\n",
    "    features[\"mid_diff\"] = features[\"mid_price\"].diff()\n",
    "    features[\"mid_return\"] = features[\"mid_diff\"] / features[\"mid_price\"].shift(1)\n",
    "    \n",
    "    features[\"total_bid_qty\"] = df[\"BID_SIZE_1\"] + df[\"BID_SIZE_2\"] + df[\"BID_SIZE_3\"]\n",
    "    features[\"total_ask_qty\"] = df[\"ASK_SIZE_1\"] + df[\"ASK_SIZE_2\"] + df[\"ASK_SIZE_3\"]\n",
    "    features[\"bid_qty_change\"] = features[\"total_bid_qty\"].diff()\n",
    "    features[\"ask_qty_change\"] = features[\"total_ask_qty\"].diff()\n",
    "    features[\"OFI\"] = features[\"bid_qty_change\"] - features[\"ask_qty_change\"]\n",
    "    \n",
    "    features[\"mv_1s\"] = features[\"mid_price\"].rolling(1000, min_periods=1).mean()\n",
    "    features[\"mv_5s\"] = features[\"mid_price\"].rolling(5000, min_periods=1).mean()\n",
    "    features[\"vol_10\"] = features[\"mid_return\"].rolling(10, min_periods=1).std()\n",
    "    features[\"vol_100\"] = features[\"mid_return\"].rolling(100, min_periods=1).std()\n",
    "    features[\"vol_1s\"] = features[\"mid_return\"].rolling(1000, min_periods=1).std()\n",
    "    features[\"vol_5s\"] = features[\"mid_return\"].rolling(5000, min_periods=1).std()\n",
    "    \n",
    "    delta = features[\"microprice\"].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14, min_periods=1).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14, min_periods=1).mean()\n",
    "    rs = gain / (loss + 1e-10)\n",
    "    features[\"rsi_14\"] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    features[\"ema_fast\"] = features[\"mid_price\"].ewm(span=12, adjust=False).mean()\n",
    "    features[\"ema_slow\"] = features[\"mid_price\"].ewm(span=26, adjust=False).mean()\n",
    "    features[\"ema_diff\"] = features[\"ema_fast\"] - features[\"ema_slow\"]\n",
    "    \n",
    "    features.drop(['total_bid_qty', 'total_ask_qty', 'bid_qty_change', 'ask_qty_change'], \n",
    "                  axis=1, inplace=True, errors='ignore')\n",
    "    \n",
    "    features = features.ffill().fillna(0)\n",
    "    features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    features = features.ffill().fillna(0)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def add_labels(features, horizon=23):\n",
    "    features['future_price'] = features['microprice'].shift(-horizon)\n",
    "    price_change = features['future_price'] - features['microprice']\n",
    "    features['target'] = 1\n",
    "    features.loc[price_change > 0, 'target'] = 2\n",
    "    features.loc[price_change < 0, 'target'] = 0\n",
    "    features.drop('future_price', axis=1, inplace=True)\n",
    "    return features\n",
    "\n",
    "# ============================================================\n",
    "# LOAD SCALER AND FEATURES\n",
    "# ============================================================\n",
    "print(\"Loading scaler and selected features...\")\n",
    "selected_features = pickle.load(open(\"C:/Users/wdkal/Downloads/IE421_XGBOOST_DATA/selected_features.pkl\", \"rb\"))\n",
    "print(f\"✓ Using {len(selected_features)} selected features\")\n",
    "\n",
    "class IdentityScaler:\n",
    "    def transform(self, X):\n",
    "        return X.values if isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "scaler = IdentityScaler()\n",
    "print(\"⚠️ Using identity scaler (no normalization)\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# PREPROCESS ONE DAY\n",
    "# ============================================================\n",
    "def preprocess_day(date):\n",
    "    file_path = RAW_DATA_PATH / f'{date}_book_updates.csv.gz'\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    df = pd.read_csv(file_path, compression='gzip')\n",
    "    df['date'] = date\n",
    "    df['COLLECTION_TIME'] = pd.to_datetime(df['COLLECTION_TIME'])\n",
    "    df = df.set_index('COLLECTION_TIME')\n",
    "    df = df.between_time(\"14:30\", \"21:00\")\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    features = add_all_features(df)\n",
    "    features = add_labels(features, horizon=23)\n",
    "    \n",
    "    X = features[selected_features]\n",
    "    y = features['target']\n",
    "    \n",
    "    X_scaled = pd.DataFrame(scaler.transform(X), columns=selected_features)\n",
    "    \n",
    "    valid_idx = ~X_scaled.isna().any(axis=1) & ~y.isna()\n",
    "    X_scaled = X_scaled[valid_idx].reset_index(drop=True)\n",
    "    y = y[valid_idx].values\n",
    "    \n",
    "    return X_scaled, y\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE PREDICTIONS WITH BATCHING\n",
    "# ============================================================\n",
    "def generate_predictions_for_day(date, xgb_model, lstm_model, tcn_model, transformer_model):\n",
    "    import time\n",
    "    import gc\n",
    "    \n",
    "    print(f\"\\nProcessing {date}...\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "    X, y = preprocess_day(date)\n",
    "    print(f\"  Events: {len(X):,} (preprocessing: {time.time()-t0:.1f}s)\")\n",
    "    \n",
    "    # 1. XGBoost\n",
    "    t0 = time.time()\n",
    "    dmatrix = xgb.DMatrix(X)\n",
    "    xgb_probs = xgb_model.predict(dmatrix)\n",
    "    \n",
    "    if len(xgb_probs.shape) == 1:\n",
    "        print(f\"    ⚠️ XGBoost output is 1D (shape={xgb_probs.shape}), reshaping...\")\n",
    "        try:\n",
    "            xgb_probs = xgb_probs.reshape(-1, 3)\n",
    "        except:\n",
    "            n_samples = len(xgb_probs)\n",
    "            xgb_probs_2d = np.zeros((n_samples, 3))\n",
    "            xgb_probs_2d[np.arange(n_samples), xgb_probs.astype(int)] = 1.0\n",
    "            xgb_probs = xgb_probs_2d\n",
    "    \n",
    "    print(f\"  XGBoost done: {time.time()-t0:.1f}s (shape={xgb_probs.shape})\")\n",
    "    \n",
    "    # 2-4. Neural networks with batching\n",
    "    X_array = X.values\n",
    "    batch_size = 10000\n",
    "    \n",
    "    # LSTM\n",
    "    print(f\"  Starting LSTM (batch_size={batch_size})...\")\n",
    "    t0 = time.time()\n",
    "    seq_len_lstm = 100\n",
    "    lstm_probs = []\n",
    "    y_seq = []\n",
    "    \n",
    "    for i in range(seq_len_lstm, len(X_array)):\n",
    "        y_seq.append(y[i])\n",
    "    \n",
    "    num_sequences = len(X_array) - seq_len_lstm\n",
    "    num_batches = (num_sequences + batch_size - 1) // batch_size\n",
    "    print(f\"    Processing {num_sequences:,} sequences in {num_batches} batches...\")\n",
    "    \n",
    "    for batch_idx, start in enumerate(range(0, num_sequences, batch_size)):\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"    LSTM batch {batch_idx+1}/{num_batches} ({100*batch_idx/num_batches:.0f}%)\")\n",
    "        \n",
    "        end = min(start + batch_size, num_sequences)\n",
    "        X_batch = []\n",
    "        for i in range(start + seq_len_lstm, end + seq_len_lstm):\n",
    "            X_batch.append(X_array[i-seq_len_lstm:i])\n",
    "        \n",
    "        if len(X_batch) > 0:\n",
    "            X_tensor = torch.FloatTensor(np.array(X_batch))\n",
    "            with torch.no_grad():\n",
    "                output = lstm_model(X_tensor)\n",
    "                probs = torch.softmax(output, dim=1).numpy()\n",
    "                lstm_probs.append(probs)\n",
    "    \n",
    "    lstm_probs = np.vstack(lstm_probs) if lstm_probs else np.array([])\n",
    "    print(f\"  LSTM done: {time.time()-t0:.1f}s\")\n",
    "    \n",
    "    # TCN\n",
    "    print(f\"  Starting TCN...\")\n",
    "    t0 = time.time()\n",
    "    seq_len_tcn = 30\n",
    "    tcn_probs = []\n",
    "    \n",
    "    num_sequences = len(X_array) - seq_len_tcn\n",
    "    num_batches = (num_sequences + batch_size - 1) // batch_size\n",
    "    \n",
    "    for batch_idx, start in enumerate(range(0, num_sequences, batch_size)):\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"    TCN batch {batch_idx+1}/{num_batches} ({100*batch_idx/num_batches:.0f}%)\")\n",
    "        \n",
    "        end = min(start + batch_size, num_sequences)\n",
    "        X_batch = []\n",
    "        for i in range(start + seq_len_tcn, end + seq_len_tcn):\n",
    "            X_batch.append(X_array[i-seq_len_tcn:i])\n",
    "        \n",
    "        if len(X_batch) > 0:\n",
    "            X_tensor = torch.FloatTensor(np.array(X_batch)).transpose(1, 2)\n",
    "            with torch.no_grad():\n",
    "                output = tcn_model(X_tensor)\n",
    "                probs = torch.softmax(output, dim=1).numpy()\n",
    "                tcn_probs.append(probs)\n",
    "    \n",
    "    tcn_probs = np.vstack(tcn_probs) if tcn_probs else np.array([])\n",
    "    print(f\"  TCN done: {time.time()-t0:.1f}s\")\n",
    "    \n",
    "    # Transformer\n",
    "    print(f\"  Starting Transformer...\")\n",
    "    t0 = time.time()\n",
    "    seq_len_transformer = 100\n",
    "    transformer_probs = []\n",
    "    \n",
    "    transformer_batch_size = 1000\n",
    "    num_sequences = len(X_array) - seq_len_transformer\n",
    "    num_batches = (num_sequences + transformer_batch_size - 1) // transformer_batch_size\n",
    "    \n",
    "    print(f\"    Processing {num_sequences:,} sequences in {num_batches} batches (batch_size={transformer_batch_size})...\")\n",
    "    \n",
    "    for batch_idx, start in enumerate(range(0, num_sequences, transformer_batch_size)):\n",
    "        if batch_idx % 100 == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - t0\n",
    "            rate = batch_idx / elapsed\n",
    "            eta = (num_batches - batch_idx) / rate\n",
    "            pct_complete = 100 * batch_idx / num_batches\n",
    "            print(f\"    Progress: {batch_idx}/{num_batches} ({pct_complete:.0f}%) - ETA: {eta/60:.1f} min\")\n",
    "        \n",
    "        end = min(start + transformer_batch_size, num_sequences)\n",
    "        \n",
    "        batch_len = end - start\n",
    "        X_batch = np.zeros((batch_len, seq_len_transformer, X_array.shape[1]), dtype=np.float32)\n",
    "        \n",
    "        for j, i in enumerate(range(start + seq_len_transformer, end + seq_len_transformer)):\n",
    "            X_batch[j] = X_array[i-seq_len_transformer:i]\n",
    "        \n",
    "        X_tensor = torch.FloatTensor(X_batch)\n",
    "        with torch.no_grad():\n",
    "            output = transformer_model(X_tensor)\n",
    "            probs = torch.softmax(output, dim=1).numpy()\n",
    "            transformer_probs.append(probs)\n",
    "        \n",
    "        del X_batch, X_tensor, output, probs\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            gc.collect()\n",
    "    \n",
    "    transformer_probs = np.vstack(transformer_probs) if transformer_probs else np.array([])\n",
    "    print(f\"  Transformer done: {time.time()-t0:.1f}s ({len(transformer_probs):,} predictions)\")\n",
    "    \n",
    "    # Align predictions\n",
    "    start_idx = 100\n",
    "    min_len = min(len(xgb_probs) - start_idx, len(lstm_probs), len(tcn_probs), len(transformer_probs))\n",
    "    \n",
    "    print(f\"\\n  Alignment summary:\")\n",
    "    print(f\"    XGBoost: {len(xgb_probs):,} predictions (using {start_idx}:{start_idx+min_len})\")\n",
    "    print(f\"    LSTM: {len(lstm_probs):,} predictions (using 0:{min_len})\")\n",
    "    print(f\"    TCN: {len(tcn_probs):,} predictions (using 0:{min_len})\")\n",
    "    print(f\"    Transformer: {len(transformer_probs):,} predictions (using 0:{min_len})\")\n",
    "    print(f\"    Final aligned length: {min_len:,}\")\n",
    "    \n",
    "    predictions_df = pd.DataFrame({\n",
    "        'actual': y_seq[:min_len],\n",
    "        'xgb_pred': xgb_probs[start_idx:start_idx+min_len].argmax(axis=1),\n",
    "        'xgb_prob_down': xgb_probs[start_idx:start_idx+min_len, 0],\n",
    "        'xgb_prob_neutral': xgb_probs[start_idx:start_idx+min_len, 1],\n",
    "        'xgb_prob_up': xgb_probs[start_idx:start_idx+min_len, 2],\n",
    "        'lstm_pred': lstm_probs[:min_len].argmax(axis=1),\n",
    "        'lstm_prob_down': lstm_probs[:min_len, 0],\n",
    "        'lstm_prob_neutral': lstm_probs[:min_len, 1],\n",
    "        'lstm_prob_up': lstm_probs[:min_len, 2],\n",
    "        'tcn_pred': tcn_probs[:min_len].argmax(axis=1),\n",
    "        'tcn_prob_down': tcn_probs[:min_len, 0],\n",
    "        'tcn_prob_neutral': tcn_probs[:min_len, 1],\n",
    "        'tcn_prob_up': tcn_probs[:min_len, 2],\n",
    "        'transformer_pred': transformer_probs[:min_len].argmax(axis=1),\n",
    "        'transformer_prob_down': transformer_probs[:min_len, 0],\n",
    "        'transformer_prob_neutral': transformer_probs[:min_len, 1],\n",
    "        'transformer_prob_up': transformer_probs[:min_len, 2],\n",
    "    })\n",
    "    \n",
    "    output_file = OUTPUT_PATH / f\"predictions_{date}.csv\"\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n  Accuracies:\")\n",
    "    for model_name in ['xgb', 'lstm', 'tcn', 'transformer']:\n",
    "        acc = (predictions_df[f'{model_name}_pred'] == predictions_df['actual']).mean()\n",
    "        print(f\"    {model_name.upper():12s}: {acc:.3f}\")\n",
    "    print(f\"  ✓ Saved {output_file}\")\n",
    "    \n",
    "    return predictions_df\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE PREDICTIONS FOR ALL DAYS\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"GENERATING PREDICTIONS ON DAYS 6-15\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Processing {len(NEW_DAYS)} days: {NEW_DAYS[0]} to {NEW_DAYS[-1]}\\n\")\n",
    "\n",
    "all_predictions = {}\n",
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "for date in NEW_DAYS:\n",
    "    try:\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        \n",
    "        preds = generate_predictions_for_day(date, xgb_model, lstm_model, tcn_model, transformer_model)\n",
    "        all_predictions[date] = preds\n",
    "        successful += 1\n",
    "        \n",
    "        del preds\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ ERROR processing {date}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        failed += 1\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICTION GENERATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Successfully processed: {successful}/{len(NEW_DAYS)} days\")\n",
    "print(f\"Failed: {failed}/{len(NEW_DAYS)} days\")\n",
    "print(f\"Output directory: {OUTPUT_PATH}\")\n",
    "\n",
    "if successful > 0:\n",
    "    print(\"\\n✅ Ready for Step 2: Combining predictions for RL training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_fresh",
   "language": "python",
   "name": "pytorch_fresh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
